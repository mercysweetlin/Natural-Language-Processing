{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99046ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7945f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['run', 'ran', 'do', 'fairli']\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "words = [\"running\", \"ran\", \"doing\", \"fairly\"]\n",
    "# Apply stemming\n",
    "stemmed_words = [ps.stem(word) for word in words]\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ab88ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokens:  ['This', 'is', 'the', 'first', 'NLP', 'class']\n",
      "Sentence tokens:  ['A hungry fox once looked everywhere for food.', 'He couldn’t find anything until he stumbled upon a farmer’s wall.']\n",
      "Punctuation Tokenizer:  ['I', 'can', \"'\", 't', 'allow', 'you', 'to', 'go', 'home', 'early']\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokens = word_tokenize('This is the first NLP class')\n",
    "print(\"Word tokens: \",tokens)\n",
    "text = \"A hungry fox once looked everywhere for food. He couldn’t find anything until he stumbled upon a farmer’s wall.\"\n",
    "s_tokens = sent_tokenize(text)\n",
    "print(\"Sentence tokens: \",s_tokens)\n",
    "tokenizer = WordPunctTokenizer()\n",
    "p_tokens = tokenizer.tokenize(\"I can't allow you to go home early\")\n",
    "print(\"Punctuation Tokenizer: \",p_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38a23f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'pen', 'table']\n"
     ]
    }
   ],
   "source": [
    "#Stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "words = \"There is a pen on the table\"\n",
    "tokens = word_tokenize(words)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered = [word for word in tokens if word not in stop_words]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0509c",
   "metadata": {},
   "source": [
    "Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ded9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  fish.n.01\n",
      "Definition:  any of various mostly cold-blooded aquatic vertebrates usually having scales and breathing through gills\n",
      "Examples:  ['the shark is a large fish', 'in the living room there was a tank of colorful fish']\n"
     ]
    }
   ],
   "source": [
    "#Wordnet\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "syn = wn.synsets('fish')[0]\n",
    "print(\"Name: \",syn.name())\n",
    "print(\"Definition: \",syn.definition())\n",
    "print(\"Examples: \",syn.examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbe1528-e744-4e89-892b-a98fd98e3793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Barack/NNP)\n",
      "  (PERSON Obama/NNP)\n",
      "  was/VBD\n",
      "  the/DT\n",
      "  44th/JJ\n",
      "  President/NNP\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (GPE United/NNP States/NNPS)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "from nltk import ne_chunk, pos_tag\n",
    "\n",
    "text = \"Barack Obama was the 44th President of the United States.\"\n",
    "# Tokenize words and perform POS tagging\n",
    "tokens = word_tokenize(text)\n",
    "pos_tags = pos_tag(tokens)\n",
    "# Perform Named Entity Recognition\n",
    "entities = ne_chunk(pos_tags)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f85b4146-623f-4212-96d2-7ac74d4ea789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S              \n",
      "      ____________|___            \n",
      "     |                VP         \n",
      "     |             ___|___        \n",
      "     NP           |       NP     \n",
      "  ___|_____       |    ___|___    \n",
      " AT       NNS    VBD  AT     NNS \n",
      " |         |      |   |       |   \n",
      "the     children ate the     cake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Parse Tree\n",
    "\n",
    "from nltk import CFG, ChartParser\n",
    "\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> AT NNS\n",
    "    VP -> VBD NP\n",
    "    PP -> P NP\n",
    "    AT -> 'the'\n",
    "    NNS -> 'children' | 'cake' \n",
    "    VBD -> 'ate'\n",
    "    P -> 'on'\n",
    "\"\"\")\n",
    "\n",
    "parser = ChartParser(grammar)\n",
    "sentence = \"the children ate the cake\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    tree.pretty_print()\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "610fec52-929e-490a-91c8-e93f5242346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> AT NNS\n",
    "    VP -> V NP\n",
    "    PP -> P NP\n",
    "    AT -> 'the'\n",
    "    NP -> 'sushi' | 'chopsticks' |'Mark'\n",
    "    V -> 'eat'\n",
    "    P -> 'on' | 'with'\n",
    "\"\"\")\n",
    "\n",
    "parser = ChartParser(grammar)\n",
    "sentence = \"Mark eat sushi with chopsticks\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "212879c0-48a5-4e65-ba03-ce1336df5f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Extracting\n",
      " (S (NP eat/NN) (NP sushi/NN) (P with/IN) chopsticks/NNS)\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, word_tokenize, RegexpParser\n",
    "  \n",
    "# Example text\n",
    "sample_text = \"eat sushi with chopsticks\"\n",
    "  \n",
    "# Find all parts of speech in above sentence\n",
    "tagged = pos_tag(word_tokenize(sample_text))\n",
    "  \n",
    "#Extract all parts of speech from any text\n",
    "chunker = RegexpParser(\"\"\"\n",
    "                       NP: {<DT>?<JJ>*<NN>}    #To extract Noun Phrases\n",
    "                       P: {<IN>}               #To extract Prepositions\n",
    "                       V: {<V.*>}              #To extract Verbs\n",
    "                       PP: {<p> <NP>}          #To extract Prepositional Phrases\n",
    "                       VP: {<VP> <NP|PP>*}      #To extract Verb Phrases\n",
    "                       \"\"\")\n",
    " \n",
    "# Print all parts of speech in above sentence\n",
    "output = chunker.parse(tagged)\n",
    "print(\"After Extracting\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc0c3c88-0bbf-4d38-9db4-539a55652a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguity detected. Multiple parses found.\n",
      "                 S                                \n",
      "      ___________|_______                          \n",
      "     |                   VP                       \n",
      "     |        ___________|________                 \n",
      "     |       |       |            PP              \n",
      "     |       |       |        ____|___             \n",
      "     NP      |       NP      |        NP          \n",
      "  ___|___    |    ___|___    |     ___|______      \n",
      "Det      N   V  Det      N   P   Det         N    \n",
      " |       |   |   |       |   |    |          |     \n",
      "the     cat saw the     dog with the     telescope\n",
      "\n",
      "                 S                            \n",
      "      ___________|___                          \n",
      "     |               VP                       \n",
      "     |        _______|___                      \n",
      "     |       |           NP                   \n",
      "     |       |    _______|____                 \n",
      "     |       |   |   |        PP              \n",
      "     |       |   |   |    ____|___             \n",
      "     NP      |   |   |   |        NP          \n",
      "  ___|___    |   |   |   |     ___|______      \n",
      "Det      N   V  Det  N   P   Det         N    \n",
      " |       |   |   |   |   |    |          |     \n",
      "the     cat saw the dog with the     telescope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Det N | Det N PP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "Det -> 'the' | 'a'\n",
    "N -> 'cat' | 'dog' | 'mat' | 'telescope'\n",
    "V -> 'saw' | 'ate'\n",
    "P -> 'on' | 'with'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "sentence = \"the cat saw the dog with the telescope\".split()\n",
    "\n",
    "parses = list(parser.parse(sentence))\n",
    "\n",
    "if len(parses) > 1:\n",
    "    print(\"Ambiguity detected. Multiple parses found.\")\n",
    "    for tree in parses:\n",
    "        tree.pretty_print()\n",
    "else:\n",
    "    print(\"No ambiguity detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a2f63-83c2-4c6b-87c2-b06871550cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
